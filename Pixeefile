import pandas as pd

# Load the Excel file (replace 'input.xlsx' with your actual file path)
input_file = 'input.xlsx'
output_file = 'output.xlsx'

# Read the Excel file
df = pd.read_excel(input_file)

# Initialize an empty list to store the processed DataFrames
output_dfs = []

# Loop through each set from 1 to 10
for i in range(1, 11):
    # Define the columns for the current set
    cols = ['Trace', 'application id', 'orgUuid', f'created date {i}', f'creator {i}', f'note {i}']
    
    # Check if all columns exist in the DataFrame
    if all(col in df.columns for col in cols):
        # Select the relevant columns for this set
        temp_df = df[cols].copy()
        
        # Rename the set-specific columns to generic names
        temp_df.columns = ['Trace', 'application id', 'orgUuid', 'created date', 'creator', 'note']
        
        # Append to the list of DataFrames
        output_dfs.append(temp_df)
    else:
        print(f"Set {i} columns not found, skipping.")

# Concatenate all DataFrames vertically
if output_dfs:
    final_df = pd.concat(output_dfs, ignore_index=True)
    
    # Save the result to a new Excel file
    final_df.to_excel(output_file, index=False)
    print(f"Output saved to {output_file}")
else:
    print("No valid sets found to process.")