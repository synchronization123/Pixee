#!/usr/bin/env python3
"""
Append SonarQube hotspot comments (from 'comment' array) to input.xlsx starting at column J.

Install:
  pip install requests openpyxl

What it does:
- Reads 'key' from input.xlsx header row.
- For each key, GET https://crm.sonsr.com/api/hotspots/show?hotspot=<key>
  with Basic auth: token as username, empty password.
- Expects JSON fields: key, component, project, rule, Changelog[], comment[].
- From comment[], collects: key, login, htmlText, createdAt (robust to minor name variants).
- Writes newline-joined values to columns J..M with headers:
    J: comment.key
    K: comment.login
    L: comment.htmlText
    M: comment.createdAt
"""

import os
import sys
import time
import shutil
from typing import List, Dict, Any

import requests
from requests.auth import HTTPBasicAuth
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter

# ================= Configuration =================
INPUT_XLSX = "input.xlsx"          # workbook containing a header 'key'
SHEET_NAME = None                  # None = active sheet; or set to your sheet name
BASE_URL = "https://crm.sonsr.com/api/hotspots/show"
TOKEN = "sjrjdjdjdj"               # <-- your token
HEADERS_ROW = 1                    # where column headers live (1-based)
START_COL_INDEX = 10               # J
TIMEOUT = 30
RETRY_COUNT = 3
RETRY_BACKOFF = 2
VERIFY_SSL = True
# =================================================

def build_url(base_url: str, hotspot_key: str) -> str:
    sep = "&" if "?" in base_url else "?"
    # If the given base already contains "hotspot=", normalize by replacing value
    if "hotspot=" in base_url:
        prefix = base_url.split("hotspot=", 1)[0]
        if "?" not in prefix:
            prefix = prefix.rstrip("/") + "?"
        return f"{prefix}hotspot={hotspot_key}"
    return f"{base_url}{sep}hotspot={hotspot_key}"

def find_header_column(ws, header_name: str, header_row: int = 1) -> int:
    target = header_name.strip().lower()
    for idx, cell in enumerate(ws[header_row], start=1):
        if cell.value is None:
            continue
        if str(cell.value).strip().lower() == target:
            return idx
    raise ValueError(f"Header '{header_name}' not found in row {header_row}.")

def ensure_output_headers(ws, start_col: int, header_row: int = 1):
    headers = ["comment.key", "comment.login", "comment.htmlText", "comment.createdAt"]
    for i, h in enumerate(headers):
        ws.cell(row=header_row, column=start_col + i, value=h)

def normalize_created_at(c: Dict[str, Any]) -> str:
    # Accept common variants
    return (
        c.get("createdAt")
        or c.get("created at")
        or c.get("created_at")
        or c.get("created")
        or ""
    )

def parse_comments_from_payload(data: Any) -> List[Dict[str, Any]]:
    """
    Extract comment list from the actual payload shape.
    Primary path: data["comment"] (array).
    Fallbacks: data["comments"], data["hotspot"]["comment"] / ["comments"]
    """
    comments = []
    if isinstance(data, dict):
        if isinstance(data.get("comment"), list):
            comments = data["comment"]
        elif isinstance(data.get("comments"), list):
            comments = data["comments"]
        elif isinstance(data.get("hotspot"), dict):
            h = data["hotspot"]
            if isinstance(h.get("comment"), list):
                comments = h["comment"]
            elif isinstance(h.get("comments"), list):
                comments = h["comments"]

    out = []
    for c in comments or []:
        if not isinstance(c, dict):
            continue
        out.append({
            "key": c.get("key") or c.get("id") or "",
            "login": c.get("login") or c.get("author") or "",
            "htmlText": c.get("htmlText") or c.get("text") or c.get("html") or "",
            "createdAt": normalize_created_at(c),
        })
    return out

def fetch_comments(hotspot_key: str) -> List[Dict[str, Any]]:
    url = build_url(BASE_URL, hotspot_key)
    last_exc = None
    for attempt in range(1, RETRY_COUNT + 1):
        try:
            r = requests.get(
                url,
                auth=HTTPBasicAuth(TOKEN, ""),
                timeout=TIMEOUT,
                verify=VERIFY_SSL,
            )
            if r.status_code == 401:
                raise RuntimeError("Unauthorized (401) â€” check TOKEN.")
            if r.status_code == 404:
                return []  # no such hotspot
            r.raise_for_status()
            payload = r.json()
            return parse_comments_from_payload(payload)
        except Exception as e:
            last_exc = e
            if attempt < RETRY_COUNT:
                time.sleep(RETRY_BACKOFF ** (attempt - 1))
            else:
                # Place an error marker in htmlText; keeps rows aligned
                return [{
                    "key": "",
                    "login": "",
                    "htmlText": f"[ERROR] {type(e).__name__}: {e}",
                    "createdAt": "",
                }]
    raise last_exc  # pragma: no cover

def write_comments_to_row(ws, row: int, start_col: int, comments: List[Dict[str, Any]]):
    join = lambda field: "\n".join(
        str(c.get(field, "") or "") for c in (comments or [])
    )
    ws.cell(row=row, column=start_col + 0, value=join("key"))
    ws.cell(row=row, column=start_col + 1, value=join("login"))
    ws.cell(row=row, column=start_col + 2, value=join("htmlText"))
    ws.cell(row=row, column=start_col + 3, value=join("createdAt"))

def main():
    if not os.path.exists(INPUT_XLSX):
        print(f"ERROR: '{INPUT_XLSX}' not found in {os.getcwd()}", file=sys.stderr)
        sys.exit(1)

    # Safety backup
    try:
        shutil.copyfile(INPUT_XLSX, "input_backup.xlsx")
        print("Backup created: input_backup.xlsx")
    except Exception as e:
        print(f"WARNING: backup failed: {e}")

    wb = load_workbook(INPUT_XLSX)
    ws = wb[SHEET_NAME] if SHEET_NAME else wb.active

    try:
        key_col = find_header_column(ws, "key", header_row=HEADERS_ROW)
    except ValueError as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(1)

    ensure_output_headers(ws, START_COL_INDEX, header_row=HEADERS_ROW)

    max_row = ws.max_row
    processed = 0
    for row in range(HEADERS_ROW + 1, max_row + 1):
        rk = ws.cell(row=row, column=key_col).value
        if rk is None:
            continue
        hotspot_key = str(rk).strip()
        if not hotspot_key:
            continue

        comments = fetch_comments(hotspot_key)
        write_comments_to_row(ws, row, START_COL_INDEX, comments)
        processed += 1

    wb.save(INPUT_XLSX)
    j = get_column_letter(START_COL_INDEX)
    m = get_column_letter(START_COL_INDEX + 3)
    print(f"Done. Wrote comment fields to {j}:{m} for {processed} key(s).")

if __name__ == "__main__":
    main()